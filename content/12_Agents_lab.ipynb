{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f576feb4",
   "metadata": {},
   "source": [
    "# Simple Semantic Kernel Agent Tutorial\n",
    "\n",
    "Learn to build AI agents with Semantic Kernel in just a few steps. This tutorial covers the essentials: creating agents, adding tools, and managing conversations.\n",
    "\n",
    "There are three foundational components in Semantic Kernel agents:‚Ä®\n",
    "1. Agent Class: All agent types inherit from this class. Agent types include ChatCompletionAgent (uses standard chat completion APIs), OpenAIAssistantAgent (leverages OpenAI Assistant API with built in tools), AzureAIAgent (integrates with Azure AI services for enterprise scenarios), CopilotStudioAgent (connects to Microsoft Copilot Studio workflows). \n",
    "2. Agent Thread: This handles how conversation history and state are maintained. This is important since agents need context from previous messages to make informed decisions. There are two approaches:\n",
    "    1. Service managed state: An agent service like Azure AI stores conversation history server-side, and accessed via thread ID.\n",
    "    2. Application managed state: Your application maintains the full chat history and passes it to the agent on each call. \n",
    "3. Agent orchestration: The framework provides pre-built patterns for coordinating multiple agents to handle complex workflows that single agents cannot manage effectively. \n",
    "    1. Sequential: Agents execute one after the other in order. This is like document processing pipeline.\n",
    "    2. Concurrent: Multiple agents working at the same time. Like customer inquiry handling (billing agent and account agent working in parallel).\n",
    "    3. Handoff: Agents pass control to each other based on specialization. Like customer service triage to specialist agent.\n",
    "    4. Group chat: Agents collaborate in a shared conversation. Like project planning with domain experts. \n",
    "\n",
    "Agents leverage Semantic Kernel‚Äôs plugin system to access tools, databases, etc. \n",
    "\n",
    "Agents can also be defined using YAML.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install required packages and configure your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75516b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install semantic-kernel python-dotenv\n",
    "\n",
    "# Import everything we need\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13891ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API key is configured\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"‚ö†Ô∏è  Please add OPENAI_API_KEY to your .env file!\")\n",
    "    print(\"   Create a .env file with: OPENAI_API_KEY=your_actual_key_here\")\n",
    "else:\n",
    "    print(\"‚úÖ API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f7752a",
   "metadata": {},
   "source": [
    "## Step 1: Create a Simple Agent\n",
    "\n",
    "Let's start with the basics - an agent that can chat. We are simply giving the kernel (our orchestrator) access to chat service, which leverages the Chat Completion API endpoint from Open AI. We will add more tools later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e3f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create service and kernel\n",
    "chat_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "kernel = Kernel()\n",
    "kernel.add_service(chat_service)\n",
    "\n",
    "# Create a basic agent\n",
    "agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful and friendly assistant.\"\n",
    ")\n",
    "\n",
    "# Test it\n",
    "response = await agent.get_response(\"Hello! What can you help me with?\")\n",
    "print(f\"ü§ñ {agent.name}: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c099c8",
   "metadata": {},
   "source": [
    "## Step 2: Add Tools (Functions)\n",
    "\n",
    "Now let's give our agent some useful capabilities. We will give it a weather function and a calculator. Both of these are functions we define in our code and provide them to the kernel as tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514017fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define useful functions\n",
    "@kernel_function(description=\"Get current weather for a city\")\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Mock weather function - replace with real API call.\"\"\"\n",
    "    weather_data = {\n",
    "        \"london\": \"Cloudy, 15¬∞C\",\n",
    "        \"paris\": \"Sunny, 22¬∞C\", \n",
    "        \"tokyo\": \"Rainy, 18¬∞C\",\n",
    "        \"new york\": \"Partly cloudy, 20¬∞C\"\n",
    "    }\n",
    "    return weather_data.get(city.lower(), f\"Weather data not available for {city}\")\n",
    "\n",
    "@kernel_function(description=\"Calculate simple math expressions\")\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Safe calculator for basic math.\"\"\"\n",
    "    try:\n",
    "        # Only allow basic math operations for safety\n",
    "        allowed_chars = \"0123456789+-*/(). \"\n",
    "        if all(c in allowed_chars for c in expression):\n",
    "            result = eval(expression)\n",
    "            return f\"{expression} = {result}\"\n",
    "        else:\n",
    "            return \"Sorry, I can only do basic math operations (+, -, *, /, parentheses)\"\n",
    "    except:\n",
    "        return \"Sorry, I couldn't calculate that. Please check your expression.\"\n",
    "\n",
    "# Add functions to kernel\n",
    "kernel.add_function(plugin_name=\"tools\", function=get_weather)\n",
    "kernel.add_function(plugin_name=\"tools\", function=calculate)\n",
    "\n",
    "# Create enhanced agent\n",
    "enhanced_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"SmartAssistant\",\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant with weather and calculator capabilities.\n",
    "    \n",
    "    - Use get_weather when asked about weather in specific cities\n",
    "    - Use calculate for math problems\n",
    "    - Be friendly and explain what you're doing\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Enhanced agent created with tools!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12f1db",
   "metadata": {},
   "source": [
    "## Step 3: Test the Agent with Tools\n",
    "\n",
    "Let's see our agent use its tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weather function\n",
    "print(\"üå§Ô∏è Testing weather function:\")\n",
    "response = await enhanced_agent.get_response(\"What's the weather in London?\")\n",
    "print(f\"ü§ñ {enhanced_agent.name}: {response.content}\\n\")\n",
    "\n",
    "# Test calculator function  \n",
    "print(\"üßÆ Testing calculator function:\")\n",
    "response = await enhanced_agent.get_response(\"What's 25 * 4 + 10?\")\n",
    "print(f\"ü§ñ {enhanced_agent.name}: {response.content}\\n\")\n",
    "\n",
    "# Test general conversation\n",
    "print(\"üí¨ Testing general conversation:\")\n",
    "response = await enhanced_agent.get_response(\"Tell me a fun fact about AI\")\n",
    "print(f\"ü§ñ {enhanced_agent.name}: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2599b5",
   "metadata": {},
   "source": [
    "## Step 4: Conversation with Memory\n",
    "\n",
    "For conversations that remember previous messages. We will use semantic kernel out of the box memory management, but that will depend on context window.\n",
    "\n",
    "Memory can be solved by summarizing past conversations or use a longer term memory like RAG. There is also learning memory where we want the agent to elarn from all past interactions, this is also implemented using RAG where we store successful resolution examples and retrieve them for similar cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_memory():\n",
    "    \"\"\"Demonstrate conversation with memory.\"\"\"\n",
    "    \n",
    "    print(\"üí≠ Conversation with Memory Demo\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Messages that build on each other\n",
    "    messages = [\n",
    "        \"Hi! I'm planning a trip to Paris.\",\n",
    "        \"What's the weather like there?\",\n",
    "        \"That sounds nice! Can you calculate 150 * 7 for my budget?\",\n",
    "        \"Perfect, that should cover my week there. Thanks!\"\n",
    "    ]\n",
    "    \n",
    "    thread = None  # This will store conversation history\n",
    "    \n",
    "    for msg in messages:\n",
    "        print(f\"üë§ User: {msg}\")\n",
    "        \n",
    "        # Agent remembers previous messages through the thread\n",
    "        response = await enhanced_agent.get_response(messages=msg, thread=thread)\n",
    "        print(f\"ü§ñ {enhanced_agent.name}: {response.content}\\n\")\n",
    "        \n",
    "        # Update thread to keep conversation history\n",
    "        thread = response.thread\n",
    "\n",
    "# Run the conversation demo\n",
    "await chat_with_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fe43a",
   "metadata": {},
   "source": [
    "## Step 5: See Tools in Action (Advanced)\n",
    "\n",
    "Watch exactly what happens when your agent uses tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_tool_usage():\n",
    "    \"\"\"Show detailed tool execution.\"\"\"\n",
    "    \n",
    "    print(\"üîß Tool Usage Demo\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Callback to see tool calls\n",
    "    async def log_tool_calls(message):\n",
    "        from semantic_kernel.contents import FunctionCallContent, FunctionResultContent\n",
    "        \n",
    "        for item in message.items or []:\n",
    "            if isinstance(item, FunctionCallContent):\n",
    "                print(f\"  üîß Calling: {item.name}({item.arguments})\")\n",
    "            elif isinstance(item, FunctionResultContent):\n",
    "                print(f\"  ‚úÖ Result: {item.result}\")\n",
    "    \n",
    "    user_input = \"What's the weather in Tokyo and what's 15 + 27?\"\n",
    "    print(f\"üë§ User: {user_input}\\n\")\n",
    "    \n",
    "    # Use invoke to see intermediate steps\n",
    "    async for response in enhanced_agent.invoke(\n",
    "        messages=user_input,\n",
    "        on_intermediate_message=log_tool_calls\n",
    "    ):\n",
    "        print(f\"\\nü§ñ Final Response: {response.content}\")\n",
    "\n",
    "# Run the tool usage demo\n",
    "await show_tool_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d49f53",
   "metadata": {},
   "source": [
    "## Step 6: Streaming Responses\n",
    "\n",
    "For real-time responses (like ChatGPT):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9bd7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def streaming_demo():\n",
    "    \"\"\"Show streaming responses.\"\"\"\n",
    "    \n",
    "    print(\"\\nüåä Streaming Demo\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    print(\"üë§ User: Write a short poem about coding\")\n",
    "    print(\"ü§ñ Assistant: \", end=\"\", flush=True)\n",
    "    \n",
    "    # Stream response word by word\n",
    "    async for chunk in enhanced_agent.invoke_stream(\n",
    "        messages=\"Write a short poem about coding\"\n",
    "    ):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\")  # New line when done\n",
    "\n",
    "# Run streaming demo\n",
    "await streaming_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72910370",
   "metadata": {},
   "source": [
    "\n",
    "## Summary: What You've Learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéì What You've Built:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "summary = [\n",
    "    \"‚úÖ Basic AI agent with OpenAI\",\n",
    "    \"‚úÖ Custom tools/functions for weather and math\", \n",
    "    \"‚úÖ Conversation memory management\",\n",
    "    \"‚úÖ Tool execution monitoring\",\n",
    "    \"‚úÖ Real-time streaming responses\"\n",
    "]\n",
    "\n",
    "for item in summary:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nüöÄ Key Concepts:\")\n",
    "concepts = {\n",
    "    \"Agent\": \"AI that can reason, remember, and use tools\",\n",
    "    \"Kernel\": \"Manages AI services and functions\",\n",
    "    \"Functions\": \"Tools that extend agent capabilities\", \n",
    "    \"Thread\": \"Maintains conversation history\",\n",
    "    \"Streaming\": \"Real-time response generation\"\n",
    "}\n",
    "\n",
    "for concept, description in concepts.items():\n",
    "    print(f\"‚Ä¢ {concept}: {description}\")\n",
    "\n",
    "print(\"\\nüí° Next Steps:\")\n",
    "print(\"‚Ä¢ Try different models (gpt-4, gpt-3.5-turbo)\")\n",
    "print(\"‚Ä¢ Create custom functions for your use case\")\n",
    "print(\"‚Ä¢ Explore multi-agent conversations\")\n",
    "print(\"‚Ä¢ Add guardrails for production safety\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f737fe9",
   "metadata": {},
   "source": [
    "## Step 7: Sequential Agent Orchestration\n",
    "\n",
    "Now let's see how multiple agents can work together in a pipeline - each agent processes the output from the previous one. Notice how easy Semantic Kernel makes this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import orchestration components\n",
    "from semantic_kernel.agents import SequentialOrchestration\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "from semantic_kernel.contents import ChatMessageContent\n",
    "\n",
    "print(\"üîó Setting up Sequential Agent Pipeline\")\n",
    "print(\"=\" * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a11437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specialized agents for a marketing pipeline\n",
    "def create_marketing_pipeline():\n",
    "    \"\"\"Create three agents that work together sequentially.\"\"\"\n",
    "    \n",
    "    # Agent 1: Extract key information\n",
    "    concept_extractor = ChatCompletionAgent(\n",
    "        name=\"ConceptExtractor\",\n",
    "        instructions=\"\"\"\n",
    "        You are a marketing analyst. Given a product description, identify:\n",
    "        - Key features (bullet points)\n",
    "        - Target audience \n",
    "        - Unique selling points\n",
    "        \n",
    "        Format your output clearly with headers.\n",
    "        \"\"\",\n",
    "        kernel=kernel\n",
    "    )\n",
    "    \n",
    "    # Agent 2: Write marketing copy\n",
    "    copywriter = ChatCompletionAgent(\n",
    "        name=\"Copywriter\", \n",
    "        instructions=\"\"\"\n",
    "        You are a marketing copywriter. Take the analysis provided and write \n",
    "        compelling marketing copy (around 100-150 words). Make it engaging \n",
    "        and highlight the key benefits. Output just the marketing copy.\n",
    "        \"\"\",\n",
    "        kernel=kernel\n",
    "    )\n",
    "    \n",
    "    # Agent 3: Polish and format\n",
    "    editor = ChatCompletionAgent(\n",
    "        name=\"Editor\",\n",
    "        instructions=\"\"\"\n",
    "        You are an editor. Take the marketing copy and polish it:\n",
    "        - Fix grammar and clarity\n",
    "        - Ensure consistent tone\n",
    "        - Make it more compelling\n",
    "        - Output the final polished version\n",
    "        \"\"\",\n",
    "        kernel=kernel\n",
    "    )\n",
    "    \n",
    "    return [concept_extractor, copywriter, editor]\n",
    "\n",
    "# Create the pipeline\n",
    "marketing_agents = create_marketing_pipeline()\n",
    "print(f\"‚úÖ Created {len(marketing_agents)} specialized agents:\")\n",
    "for agent in marketing_agents:\n",
    "    print(f\"   ‚Ä¢ {agent.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93648c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up callback to see each agent's work\n",
    "def agent_callback(message: ChatMessageContent) -> None:\n",
    "    \"\"\"Show what each agent produces.\"\"\"\n",
    "    print(f\"\\nü§ñ {message.name}:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(message.content)\n",
    "    print()\n",
    "\n",
    "# Create the sequential orchestration\n",
    "sequential_pipeline = SequentialOrchestration(\n",
    "    members=marketing_agents,\n",
    "    agent_response_callback=agent_callback\n",
    ")\n",
    "\n",
    "print(\"üîó Sequential pipeline created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50da022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sequential pipeline\n",
    "async def run_marketing_pipeline():\n",
    "    \"\"\"Execute the sequential agent pipeline.\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Running Marketing Pipeline\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Start the runtime\n",
    "    runtime = InProcessRuntime()\n",
    "    runtime.start()\n",
    "    \n",
    "    try:\n",
    "        # Input: Product description\n",
    "        product_description = (\n",
    "            \"A smart water bottle with temperature display, \"\n",
    "            \"app connectivity, hydration reminders, and \"\n",
    "            \"leak-proof design. Made from BPA-free materials.\"\n",
    "        )\n",
    "        \n",
    "        print(f\"üìù Input Product: {product_description}\\n\")\n",
    "        print(\"Processing through pipeline...\")\n",
    "        \n",
    "        # Run the sequential orchestration\n",
    "        result = await sequential_pipeline.invoke(\n",
    "            task=product_description,\n",
    "            runtime=runtime\n",
    "        )\n",
    "        \n",
    "        # Get final result\n",
    "        final_output = await result.get(timeout=30)\n",
    "        \n",
    "        print(\"üéØ FINAL MARKETING COPY:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(final_output)\n",
    "        \n",
    "    finally:\n",
    "        # Clean up\n",
    "        await runtime.stop_when_idle()\n",
    "\n",
    "# Execute the pipeline\n",
    "await run_marketing_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12781dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick demo with a different product\n",
    "async def quick_pipeline_demo():\n",
    "    \"\"\"Quick demo with another product.\"\"\"\n",
    "    \n",
    "    print(\"\\nüîÑ Quick Pipeline Demo #2\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    runtime = InProcessRuntime()\n",
    "    runtime.start()\n",
    "    \n",
    "    try:\n",
    "        # Different product\n",
    "        product = \"Wireless earbuds with 30-hour battery, noise cancellation, and workout-proof design\"\n",
    "        \n",
    "        print(f\"üìù Product: {product}\")\n",
    "        \n",
    "        # Simple pipeline without detailed logging\n",
    "        simple_pipeline = SequentialOrchestration(members=marketing_agents)\n",
    "        \n",
    "        result = await simple_pipeline.invoke(\n",
    "            task=product,\n",
    "            runtime=runtime\n",
    "        )\n",
    "        \n",
    "        final_copy = await result.get(timeout=30)\n",
    "        print(f\"\\nüéØ Final Copy:\\n{final_copy}\")\n",
    "        \n",
    "    finally:\n",
    "        await runtime.stop_when_idle()\n",
    "\n",
    "# Run quick demo\n",
    "await quick_pipeline_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697c910",
   "metadata": {},
   "source": [
    "\n",
    "## Summary: What You've Learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac67069",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéì Complete Tutorial Summary:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "summary = [\n",
    "    \"‚úÖ Basic AI agent with OpenAI\",\n",
    "    \"‚úÖ Custom tools/functions for weather and math\", \n",
    "    \"‚úÖ Conversation memory management\",\n",
    "    \"‚úÖ Tool execution monitoring\",\n",
    "    \"‚úÖ Real-time streaming responses\",\n",
    "    \"‚úÖ Sequential agent orchestration\"\n",
    "]\n",
    "\n",
    "for item in summary:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nüöÄ Key Concepts:\")\n",
    "concepts = {\n",
    "    \"Agent\": \"AI that can reason, remember, and use tools\",\n",
    "    \"Kernel\": \"Manages AI services and functions\",\n",
    "    \"Functions\": \"Tools that extend agent capabilities\", \n",
    "    \"Thread\": \"Maintains conversation history\",\n",
    "    \"Streaming\": \"Real-time response generation\",\n",
    "    \"Sequential Orchestration\": \"Pipeline where agents process output sequentially\"\n",
    "}\n",
    "\n",
    "for concept, description in concepts.items():\n",
    "    print(f\"‚Ä¢ {concept}: {description}\")\n",
    "\n",
    "print(\"\\nüí° Agent Patterns:\")\n",
    "patterns = [\n",
    "    \"Single Agent: One agent handles entire workflow\",\n",
    "    \"Sequential: Agents work in pipeline (A ‚Üí B ‚Üí C)\",\n",
    "    \"Concurrent: Multiple agents work simultaneously\", \n",
    "    \"Manager: Central agent coordinates specialists\",\n",
    "    \"Handoff: Agents pass control to each other\"\n",
    "]\n",
    "\n",
    "for pattern in patterns:\n",
    "    print(f\"‚Ä¢ {pattern}\")\n",
    "\n",
    "print(\"\\nüéØ When to Use Sequential Orchestration:\")\n",
    "use_cases = [\n",
    "    \"‚Ä¢ Document processing (extract ‚Üí summarize ‚Üí format)\",\n",
    "    \"‚Ä¢ Content creation (research ‚Üí write ‚Üí edit)\", \n",
    "    \"‚Ä¢ Data analysis (collect ‚Üí analyze ‚Üí visualize)\",\n",
    "    \"‚Ä¢ Code review (analyze ‚Üí suggest ‚Üí validate)\"\n",
    "]\n",
    "\n",
    "for use_case in use_cases:\n",
    "    print(use_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dbbce4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**üîë Key Takeaways:**\n",
    "- **Single Agents**: Great for simple tasks and learning\n",
    "- **Sequential Orchestration**: Perfect for multi-step workflows where each step builds on the previous\n",
    "- **Specialization**: Each agent focuses on what it does best\n",
    "- **Pipeline Benefits**: Better quality through specialized processing\n",
    "- **Real-world Applications**: Document processing, content creation, data analysis\n",
    "\n",
    "This tutorial covers everything from basic agents to sophisticated multi-agent pipelines!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
